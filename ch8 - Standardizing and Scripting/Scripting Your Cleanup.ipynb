{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c0c92e9",
   "metadata": {},
   "source": [
    "### Our Script so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de5c9725",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mwelevel\n",
      "mnweight\n",
      "wscoreu\n",
      "windex5u\n",
      "wscorer\n",
      "windex5r\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "import dataset\n",
    "import pickle\n",
    "\n",
    "data_rdr = reader(open('mn.csv', 'r', encoding='utf-8'))\n",
    "header_rdr = reader(open('mn_headers_updated.csv', 'r', encoding='utf-8'))\n",
    "\n",
    "data_rows = [d for d in data_rdr]\n",
    "header_rows = [h for h in header_rdr if h[0] in data_rows[0]]\n",
    "\n",
    "all_short_headers = [h[0] for h in header_rows]\n",
    "skip_index = []\n",
    "final_header_rows = []\n",
    "\n",
    "for header in data_rows[0]:\n",
    "    if header not in all_short_headers:\n",
    "        print(header)\n",
    "        index = data_rows[0].index(header)\n",
    "        if index not in skip_index:\n",
    "            skip_index.append(index)\n",
    "    else:\n",
    "        for head in header_rows:\n",
    "            if head[0] == header:\n",
    "                final_header_rows.append(head)\n",
    "                break\n",
    "new_data = []\n",
    "\n",
    "for row in data_rows[1:]:\n",
    "    new_row = []\n",
    "    \n",
    "    for i, d in enumerate(row):\n",
    "        if i not in skip_index:\n",
    "            new_row.append(d)\n",
    "    new_data.append(new_row)\n",
    "\n",
    "zipped_data = []\n",
    "for drow in new_data:\n",
    "    zipped_data.append(zip(final_header_rows, drow))\n",
    "    \n",
    "# Save the list to a file\n",
    "with open('zipped_data.pkl', 'wb') as file:\n",
    "    pickle.dump(zipped_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1c36412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the list from the file\n",
    "def load_zipped_data():\n",
    "    with open('zipped_data.pkl', 'rb') as file:\n",
    "        zipped_data = pickle.load(file)\n",
    "        return zipped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cde9f85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for missing\n",
    "zipped_data = load_zipped_data()\n",
    "for x in zipped_data[0]:\n",
    "    if not x[1]:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7fe312c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "#look for duplicates\n",
    "\n",
    "set_of_keys = set()\n",
    "zipped_data = load_zipped_data()\n",
    "for x in zipped_data:\n",
    "    unique_key = ''\n",
    "    for i, row in enumerate(x):\n",
    "        if i in [0, 1, 2]:\n",
    "            unique_key += str(row[1])+'-'\n",
    "    set_of_keys.add(unique_key[:-1])\n",
    "\n",
    "uniques = []\n",
    "zipped_data = load_zipped_data()\n",
    "for x in zipped_data:\n",
    "    unique_key = ''\n",
    "    for i, row in enumerate(x):\n",
    "        if i in [0, 1, 2]:\n",
    "            unique_key += str(row[1])+'-'\n",
    "    if not set_of_keys.remove(unique_key[:-1]):\n",
    "        uniques.append(x)\n",
    "        \n",
    "print(set_of_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a7d3215",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to db\n",
    "zipped_data = load_zipped_data()\n",
    "db = dataset.connect('sqlite:///data_wrangling.db')\n",
    "table = db['unicef_survey']\n",
    "\n",
    "for row_num, data in enumerate(zipped_data):\n",
    "    for question, answer in data:\n",
    "        data_dict = {\n",
    "            'question': question[1],\n",
    "            'question_code': question[0],\n",
    "            'answer': answer,\n",
    "            'response_number': row_num,\n",
    "            'survery': 'mn',\n",
    "        }\n",
    "    table.insert(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25af49b1",
   "metadata": {},
   "source": [
    "#### we can see most of our code is flat, meaning we don't have nested levels of importance. Much of the code and functions sit without identation or documentation in the file. It's not well abstracted, and the variable names are unclear. let's start working on parts of that, beginning at the top. The first two sets of lines repeat each other. Let's write a function to do that instead."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-wrangling",
   "language": "python",
   "name": "data-wrangling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
